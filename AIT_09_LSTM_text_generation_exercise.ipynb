{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lacykaltgr/ait-assessments/blob/main/AIT_09_LSTM_text_generation_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abUaqGlYI3w9"
      },
      "source": [
        "# Copyright\n",
        "<pre>\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "\n",
        "The following source was used when creating this code:\n",
        "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
        "\n",
        "Copyright (c) 2023 Bálint Gyires-Tóth - All Rights Reserved\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQY4NwcOJv6A"
      },
      "source": [
        "## Character-based text generation with LSTMs\n",
        "This notebook shows how to train an LSTM with an arbitrary text corpus, and use the trained model to generate text.\n",
        "\n",
        "We start with the imports:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kbWkA6NIzoS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import re, cgi"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCqyuI1fKbbD"
      },
      "source": [
        "# 1. Dataset acquisition and data preparation\n",
        "We can use any text, the larger text corpus is expected to result in better models. Here, we download a text file from gutenberg.org:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpCW9mcSJBXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c130a7-4a39-4fb6-973f-fb75bc7affd2"
      },
      "source": [
        "url_book=\"http://www.gutenberg.org/files/2151/2151-0.txt\"\n",
        "urlretrieve(url_book, 'book.txt')\n",
        "text = open(\"book.txt\", encoding='utf-8').read().lower()\n",
        "\n",
        "print('Number of characters in the text:', len(text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters in the text: 486583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "3B2wBu050RZt",
        "outputId": "e8e8d54a-3c4d-4402-e9ff-3d2f488e4824"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffthe project gutenberg ebook of the works of edgar allan poe, volume 5, by edgar allan poe\\n\\nthis ebook is for the use of anyone anywhere in the united states and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\nof the project gutenberg license included with this ebook or online at\\nwww.gutenberg.org. if you are not located in the united states, you\\nwill have to check the laws of the country where you are located before\\nusing this ebook.\\n\\ntitle: the works of edgar allan poe, volume 5\\n\\nauthor: edgar allan poe\\n\\nrelease date: april, 2000 [ebook #2151]\\n[most recently updated: january 25, 2023]\\n\\nlanguage: english\\n\\ncharacter set encoding: utf-8\\n\\nproduced by: david widger\\nrevised by richard tonsing.\\n\\n*** start of the project gutenberg ebook the works of edgar allan poe, vol. 5 ***\\n\\n\\n\\n\\nthe works of edgar allan poe\\n\\nby edgar allan poe\\n\\nthe raven edition\\n\\nvolume v.\\n\\n\\n\\n\\ncontents\\n\\n\\n philosophy of furniture'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffthe project gutenberg ebook of the works of edgar allan poe, volume 5, by edgar allan poe\\n\\nthis ebook is for the use of anyone anywhere in the united states and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\nof the project gutenberg license included with this ebook or online at\\nwww.gutenberg.org. if you are not located in the united states, you\\nwill have to check the laws of the country where you are located before\\nusing this ebook.\\n\\ntitle: the works of edgar allan poe, volume 5\\n\\nauthor: edgar allan poe\\n\\nrelease date: april, 2000 [ebook #2151]\\n[most recently updated: january 25, 2023]\\n\\nlanguage: english\\n\\ncharacter set encoding: utf-8\\n\\nproduced by: david widger\\nrevised by richard tonsing.\\n\\n*** start of the project gutenberg ebook the works of edgar allan poe, vol. 5 ***\\n\\n\\n\\n\\nthe works of edgar allan poe\\n\\nby edgar allan poe\\n\\nthe raven edition\\n\\nvolume v.\\n\\n\\n\\n\\ncontents\\n\\n\\n philosophy of furniture'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__ZCGV65JMqw"
      },
      "source": [
        "If the source is a html file, the html tags should be also stripped by uncommenting the following lines. Currently, we downloaded raw txt file, so we don't need to strip HTML tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tel5BBxTJI_b"
      },
      "source": [
        "# tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
        "# no_tags = tag_re.sub('', text)\n",
        "# text = cgi.escape(no_tags) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlENqpfgLHba"
      },
      "source": [
        "We calculate the unique characters of the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A6d__rGJRwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026ab161-d44e-4d47-af82-e51ab0215733"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters of the book:', len(chars))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters of the book: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4R3TAY0frj",
        "outputId": "26d94b53-9f06-467b-d48e-1be847b76c36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '=',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '{',\n",
              " '}',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ö',\n",
              " 'ú',\n",
              " 'ü',\n",
              " 'œ',\n",
              " 'α',\n",
              " 'γ',\n",
              " 'δ',\n",
              " 'ε',\n",
              " 'η',\n",
              " 'ι',\n",
              " 'λ',\n",
              " 'ν',\n",
              " 'ξ',\n",
              " 'ο',\n",
              " 'π',\n",
              " 'ρ',\n",
              " 'ς',\n",
              " 'σ',\n",
              " 'τ',\n",
              " 'υ',\n",
              " 'χ',\n",
              " 'ῆ',\n",
              " 'ῦ',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '•',\n",
              " '™',\n",
              " '\\ufeff']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StlPJfzaLPwl"
      },
      "source": [
        "Next, we create  character->index and index->character dictionaries for the one-hot encodings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ8Y0N9gJWOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf7deb4-eadb-4857-e4ee-50a2d56506db"
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print (\"Indices to char dictionary:\", indices_char)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices to char dictionary: {0: '\\n', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '&', 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '=', 27: '?', 28: '[', 29: ']', 30: '_', 31: 'a', 32: 'b', 33: 'c', 34: 'd', 35: 'e', 36: 'f', 37: 'g', 38: 'h', 39: 'i', 40: 'j', 41: 'k', 42: 'l', 43: 'm', 44: 'n', 45: 'o', 46: 'p', 47: 'q', 48: 'r', 49: 's', 50: 't', 51: 'u', 52: 'v', 53: 'w', 54: 'x', 55: 'y', 56: 'z', 57: '{', 58: '}', 59: 'à', 60: 'â', 61: 'æ', 62: 'è', 63: 'é', 64: 'ê', 65: 'ö', 66: 'ú', 67: 'ü', 68: 'œ', 69: 'α', 70: 'γ', 71: 'δ', 72: 'ε', 73: 'η', 74: 'ι', 75: 'λ', 76: 'ν', 77: 'ξ', 78: 'ο', 79: 'π', 80: 'ρ', 81: 'ς', 82: 'σ', 83: 'τ', 84: 'υ', 85: 'χ', 86: 'ῆ', 87: 'ῦ', 88: '—', 89: '‘', 90: '’', 91: '“', 92: '”', 93: '•', 94: '™', 95: '\\ufeff'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LocVYkLyLdMu"
      },
      "source": [
        "## 1.1. Creating 3D input data for the LSTM - exercise\n",
        "Split the text into 40 character long sequences with 10 characters overlap as input, and the next character as output. We will call these sequences as \"sentence\", however these are chunks of texts and not grammatically correct sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EUZeSgtJYYx"
      },
      "source": [
        "maxlen  = 40\n",
        "step    = 10   # the step size between two \"sentence\" is 10 characters\n",
        "sentences  = [] # maxlen number of characters, with \"step\" overlap between two \"sentences\" \n",
        "next_chars = [] # the next character"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkup7mdMGGE"
      },
      "source": [
        "Cut out sequences and the corresponding next characters from the corpus, where the sequence length is \"maxlen\", and the step size between two instances is \"step\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qisyd0qPJZO0"
      },
      "source": [
        "for i in range(0, len(text)-maxlen, step):\n",
        "    sentences.append(text[i:i+maxlen])\n",
        "    next_chars.append(text[i+maxlen])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2i1N-7XJbSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02236960-5902-4c52-bd2c-4f77d0318853"
      },
      "source": [
        "print('Number of training samples:', len(sentences)) # it should be 48655"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 48655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU1UmI-hMvhr"
      },
      "source": [
        "Creating NumPy arrays with the correct shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH3vNrQrJcxy"
      },
      "source": [
        "X = np.zeros((len(sentences), maxlen, len(chars)))\n",
        "y = np.zeros((len(sentences), len(chars)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKJobG0yM4D6"
      },
      "source": [
        "Introducing one-hot encodings to the NumPy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[139], char_indices[next_chars[139]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GMCEy5_70lW",
        "outputId": "5eb74a53-6de1-476b-f14f-212167db33da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('s s. osgood\\n eldorado\\n to marie louise (', 49)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[140]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Gzbl8qX8Ed5",
        "outputId": "ae0bd0ac-9f25-46c9-b34c-6cef076f5a38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'d\\n eldorado\\n to marie louise (shew)\\n o m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKCmrCPJeWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8221feea-88b9-47be-e440-bccc9ea3b73e"
      },
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence): \n",
        "        X[i,t,char_indices[char]] = 1\n",
        "    y[i,char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print (\"Shape of the input data:\", X.shape)\n",
        "print (\"Shape of the target data:\", y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input data: (48655, 40, 96)\n",
            "Shape of the target data: (48655, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for char in \"hello\":\n",
        "  print(char_indices[char])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF0x2C3g8YzX",
        "outputId": "44695907-0dc4-41a9-b284-9e954988f2b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n",
            "35\n",
            "42\n",
            "42\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmRQ_ptkNSTS"
      },
      "source": [
        "# 2. Model definition\n",
        "We define a simple LSTM model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMWAOmCDJjLM"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[-2], X.shape[-1]))) # (batch, 128)\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R67fHMGcIoEg",
        "outputId": "e8dc850e-201c-41d7-e5f5-0217db3a88dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               115200    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                12384     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 96)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,584\n",
            "Trainable params: 127,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KUmJwjlNUjJ"
      },
      "source": [
        " Compiling the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jNSADEEJk9W"
      },
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWec07qYNW6J"
      },
      "source": [
        "# 3. Training and evaluation\n",
        "In this part we will perform training and evaluation together. As this is a generative model, it is not easy to evaluate it automatically. Now, we just generate some text with an input prompt during training the model. \n",
        "\n",
        "## 3.1. Sampling functions for evaluation\n",
        "\n",
        "Sampling the prediction, where the temperature's value controls the probability of selecting the highest value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhb7onnPJoCk"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds) \n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas), preds\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NceyMw2NxjM"
      },
      "source": [
        "Testing the sample function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un01jbmWJp-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f93d17-ebce-4f2f-b376-c3505534c4d0"
      },
      "source": [
        "fake_preds=[0.1, 0.2, 0.3, 0.15, 0.25] # 1\n",
        "for temp in [0.1, 0.5, 1, 2, 4]:\n",
        "    print(fake_preds)\n",
        "    proba, preds = sample(fake_preds,temp)\n",
        "    print(preds)\n",
        "    print(proba)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[1.43537082e-05 1.46981972e-02 8.47572114e-01 8.27707142e-04\n",
            " 1.36887628e-01]\n",
            "2\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.04444444 0.17777778 0.4        0.1        0.27777778]\n",
            "4\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.1  0.2  0.3  0.15 0.25]\n",
            "0\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.14384043 0.20342109 0.24913894 0.17616783 0.2274317 ]\n",
            "2\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.17037527 0.20261148 0.22422646 0.18855123 0.21423556]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf0Y6ia0N7ee"
      },
      "source": [
        "## 3.2. Training and text generation\n",
        "The following code block does training for 10 epochs then generates text with different temperatures, and continiues training and and text generation again and again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRuiJTLEJr9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38f02bc4-da9d-4117-f2ec-24246ea47c4c"
      },
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1) # random starting point\n",
        "for iteration in range(1, 10):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(X, y, batch_size=128, epochs=10)\n",
        "    \n",
        "    for temp in [0.4, 1.0, 1.2]: # changing the \"temperature\"\n",
        "        print()\n",
        "        print('----- temperature:', temp)\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen] \n",
        "        generated += sentence\n",
        "        print('----- Generating with initial text: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(200): # we generate 400 characters\n",
        "            # creating the one-hot encoded input for the LSTM\n",
        "            x = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "              x[0, t, char_indices[char]] = 1\n",
        "            preds = model.predict(x, verbose=0)[0] # forward pass\n",
        "            next_index,_ = sample(preds, temp) # sampling the predictions with \"temperature\"\n",
        "            next_char = indices_char[next_index] # converting the prediction to character\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char # we add the generated character to the input and delete the first character to keep it \"maxlen\" long\n",
        "\n",
        "            sys.stdout.write(next_char) # we print the character\n",
        "            sys.stdout.flush()\n",
        "       \n",
        "        preds=next_index=next_char=generated=sentence=\"\"\n",
        "\n",
        "        print()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 10s 7ms/step - loss: 2.4166\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 2.0025\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.8586\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.7621\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.6761\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.5969\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.5269\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.4649\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.4063\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.3642\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good and the worldsh were from the\n",
            "      mr. poets, shadow for the the present\n",
            "      means of the speriests were amony heart\n",
            "      the stars of the saves of the early\n",
            "      the speaked from the early wor\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goods” the scill a porred and paetle\n",
            "_heje.\n",
            "\n",
            "3 croust should damb’s your thiseligatement, charbercess\n",
            "come and monum when!\n",
            "  the warks\n",
            "     a pashesm! at wav, intended gath finculled\n",
            "      upon theense d\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goots, bawn!\n",
            "  their seef’s eacthery—“dreahon’z, in enlon)”)\n",
            "  deligated so bun’s many &’t, may in the\n",
            "      mosumb them” contlies of he veated dogztow\n",
            "  } melowiw-oreation-i wai\n",
            "      nagds nealieg—the \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.3248\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.2909\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.2594\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.2430\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.2253\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.2068\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1863\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.1735\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1615\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1490\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good in the most not the sould belingue\n",
            "      in the love of the stars, and they well a dearth and the hout noticacle who as the arss the ear\n",
            "      of the project guttles it was again the anderantly poet\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goo my stand, in thes\n",
            "      vent right,w’s wills.\n",
            "\n",
            "      heloch of ane onctone,) and the anister difuss of trecessed under the\n",
            "      mens repurd putiden was conscoute oneding the nop,\n",
            "re shand, bacest to\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares gootser feays\n",
            "     that take. ’ti, are no moan.\n",
            "     iffices undirevedlew is.\n",
            "\n",
            "     quetustering enlittancextlzery little frich!pibed—and hannor ser\n",
            "      unully goneritianiss!\n",
            "         tap on—cheer, ξou\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.1415\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1353\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1260\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.1077\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0967\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.0868\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0770\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0671\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0604\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0609\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goodsication of the dead?\n",
            "                                                                                                                                                                                 \n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goods. i fect one, my long,\n",
            "     is cher, i reason was noker. will have not on eary—hat intoar as at rasts.\n",
            "     by the most sow:—fok some—thore was at rived. jeeve at possicion allan who _say,\n",
            "      an \n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good some layal atstreod, and wouldsse‘—they provelrss of brow, and rumbrnen, airmarτ\n",
            "      a methou loédly over from imppores by the —\n",
            "     th; give but . nf     on the should have provers, very prover \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0480\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0398\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 1.0300\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0308\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0166\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 1.0062\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9974\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9958\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 0.9826\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9761\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good and lade all thing his soling\n",
            "      through the revenge’s compured dount, and things and allome\n",
            "                                                                                                      \n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good apon exclied to musting in a took gotins. the rethming into form incosely compate vice impropely a willid suchisting to windyok menerflyss\n",
            "\n",
            "\n",
            "                ). they distover the divgy-stance at ald \n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares goots bady pub-s\n",
            ". the stirγlich-wittly hald yee\n",
            "      mmany everication smayes, all, i    by the joes of it is tyes\n",
            "      leaw it viginse it was awharver\n",
            "         band i onies—\n",
            "     cas.     heaven twat\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 3s 8ms/step - loss: 0.9677\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9576\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9539\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9456\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9377\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 0.9374\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9310\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9262\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9217\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9108\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good as he had rigne for the spirit,\n",
            "      the commontly and the shadowy followed\n",
            "          the shent sentain so dich is such dond it a gree and seven of the suppol. the solicius of the speak of concess \n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good and coverate aske before to towardst r;land\n",
            " whom ers. havewy”)\n",
            "     apon her than sha\n",
            "      baching comply\n",
            "     the strange _on the blutts was the ask he said\n",
            "      of eally yes, for the hummer, an\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"n lately of thy wedding.\n",
            "  how fares goo\"\n",
            "n lately of thy wedding.\n",
            "  how fares good be,\n",
            "     _had nat brow, pol.  of silen reepe by vidfelion chare,\n",
            " some fullin.\n",
            "\n",
            "      her fectiver _tooden worthy, gark e,—lot is penuse\n",
            "      his eye not bight. ih very all thy window, thaod men th\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.9099\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8968\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8998\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 3s 7ms/step - loss: 0.8919\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8909\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8807\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8797\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8719\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 3s 8ms/step - loss: 0.8661\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 2s 6ms/step - loss: 0.8546\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-46d490f1d68f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# changing the \"temperature\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xJjfgADOoPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}